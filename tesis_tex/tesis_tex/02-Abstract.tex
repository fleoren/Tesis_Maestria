\prefacesection{Abstract}

Este trabajo de Tesis propone representar el conocido \textit{Juego de la Distribuci\'on de Cerveza} como un modelo multiagente de cadena de suministro, a\~nadiendo una restricci\'on tal que se aproxime m\'as a un problema del mundo real: la producci\'on de materia prima es finita y solamente ocurre en un periodo espec\'ifico. El acercamiento elegido es la aplicaci\'on de dos m\'etodos de aprendizaje reforzado: \textit{Policy Iteration} y \textit{Q-learning}; ambas t\'ecnicas encuentran estrategias aplicables para todos los agentes. Se demuestra que con \textit{Policy Iteration} se encuentra un conjunto de pol\'iticas que les reportan mayores utilidades que algunas estrategias b\'asicas, bajo un esquema de recompensas y castigos. Por otro lado, \textit{Q-learning} demuestra ser un algoritmo pesado computacionalmente y, aunque proporciona estrategias para los agentes, no puede responder a cambios tan r\'apidamente como \textit{Policy Iteration}.\\

Se concluye que el aprendizaje reforzado no solamente es eficiente, sino suficientemente flexible como para identificar cambios permanentes en la demanda y adaptar las consecuentes pol\'iticas de compra. Asimismo, se muestra evidencia de que para cada agente en la cadena, es preferible seguir estrategias optimizadas independientemente de las decisiones de los dem\'as agentes. Finalmente, se explora la posibilidad de que en subsecuentes trabajos, se a\~nadan estrategias diferentes o restricciones adicionales al \textit{Problema de la Distribuci\'on de la Cerveza} para obtener modelos m\'as fieles a las condiciones del mundo externo y, por lo tanto, utilizables en un contexto real.\\

\textbf{T\'erminos clave}
Juego de la Distribuci\'on de Cerveza, Aprendizaje Reforzado, Iteraci\'on de Pol'itica, Q-aprendizaje
